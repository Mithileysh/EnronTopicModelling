This uses gensim's online latent dirichlet allocation implementation to topic model the Enron Email dataset. The Enron
Emails contain 517,431 emails from 150 Enron executive accounts covering a period from December 1979 through February
2004, with the majority of emails occurring during 1999, 2000, and 2001. After training, we can infer 50 latent topics
in the corpus. Topics are interpreted by their probability distribution over words.

Example topic word distributions:

topic #31: 0.003*market + 0.002*trading + 0.002*risk + 0.002*management + 0.002*million + 0.002*companies + 0.002*services + 0.002*markets 
topic #0: 0.013*intended + 0.011*recipient + 0.006*confidential + 0.005*privileged + 0.005*prohibited + 0.005*attachments + 0.005*sender
topic #3: 0.005*im + 0.005*she + 0.004*her + 0.004*hope + 0.004*night + 0.003*really + 0.003*weekend + 0.003*hey + 0.003*ill + 0.003*love
topic #4: 0.020*sally + 0.012*beck + 0.010*becks + 0.009*sbecknsf + 0.007*sallybeckdec + 0.004*risk + 0.004*operations + 0.004*patti
topic #29: 0.020*image + 0.006*click + 0.005*free + 0.005*order + 0.004*amazoncom + 0.004*online + 0.004*shipping + 0.004*card + 0.003*training
topic #14: 0.014*image + 0.009*travel + 0.006*fares + 0.006*hotel + 0.005*mailbox + 0.004*airlines + 0.004*flight + 0.004*fare + 0.004*mwhitt

We can also infer, for each email, a probability distribution over topics. Tagging emails with their most likely topic 
and then clustering them can help with information retrieval. After training, each email is assigned it's most likely
topic and stored in mongodb.

The Enron emails can be obtained here: http://www.cs.cmu.edu/~enron/

Dependencies:

* gensim - online (memory-independent) topic modeling. Read more here: http://radimrehurek.com/gensim/
* pymongo
* matplotlib for plotting analysis of email topic distributions
